{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c24b273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision \n",
    "import pathlib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5c986e",
   "metadata": {},
   "source": [
    "$\\Large\\text{Data load}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "26589fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder = 'TOP4040/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "614dc327",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(path_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d7f18488",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(path_folder + '3.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6a0bf3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13900eda0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[6], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510d07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5210208c",
   "metadata": {},
   "source": [
    "$\\Large\\text{Examples of tensor usage}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b56fc848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3235, 0.2373, 0.3899, 0.9566, 0.8621, 0.5881],\n",
       "        [0.0527, 0.4767, 0.0014, 0.5825, 0.1796, 0.8955],\n",
       "        [0.2290, 0.8728, 0.5346, 0.6704, 0.2093, 0.2219],\n",
       "        [0.2280, 0.2104, 0.0355, 0.0975, 0.7820, 0.1833],\n",
       "        [0.3402, 0.3883, 0.7353, 0.0828, 0.2805, 0.3539],\n",
       "        [0.5667, 0.0642, 0.5070, 0.4360, 0.3403, 0.9218]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(6,6)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b93d4b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3235, 0.2373, 0.3899, 0.9566, 0.8621, 0.5881, 0.0527, 0.4767, 0.0014,\n",
       "        0.5825, 0.1796, 0.8955, 0.2290, 0.8728, 0.5346, 0.6704, 0.2093, 0.2219,\n",
       "        0.2280, 0.2104, 0.0355, 0.0975, 0.7820, 0.1833, 0.3402, 0.3883, 0.7353,\n",
       "        0.0828, 0.2805, 0.3539, 0.5667, 0.0642, 0.5070, 0.4360, 0.3403, 0.9218])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ca5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.view(3,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.view(-1, 12) # -1 , python automatically calculate the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a31a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7643b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.numpy() #have to write copy(), otherwise they are stored at the same memory\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a.numpy().copy() #have to write copy(), otherwise they are stored at the same memory and whenever you change the value in a it is also changed in b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e1073",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.add_(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0afc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4960f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5, requires_grad = True)\n",
    "x # it says to tensor that later it requires to calculate the gradients for this tensor in optimization steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d32958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x[0].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810acea",
   "metadata": {},
   "source": [
    "$\\Large\\text{Gradient calculation with autograd}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d979f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, requires_grad = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930fa45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c95614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y**2*2\n",
    "# z = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8474a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z.backward() #dz/dx\n",
    "# print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b81cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we dont specify z = z.mean()\n",
    "v = torch.tensor([0.1, 1.0, 0.001], dtype = torch.float32)\n",
    "z.backward(v) # in the backward it is vector jacobian product\n",
    "print(x.grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91792ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.requires_grad_(False)\n",
    "# x.detach()\n",
    "# with torch.no_grad():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef8217",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.requires_grad_(False) # Whenever our function has _ at the end it means that is modified our variable inplace\n",
    "x # Now x does not have requires_grad=True\n",
    "# The same will be with y = x.detach()\n",
    "# with torch.no_grad():\n",
    "#    y = x + 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf848c7",
   "metadata": {},
   "source": [
    "$\\text{Whenever we call backward function then the gradient for this tensor will be accumulated into the dot grad attribute, the values will be summed up}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e615916",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.ones(4 , requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e3441d",
   "metadata": {},
   "source": [
    "$\\text{Before we do the next iteration or optimiztion we must empty the gradients}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8bf10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(4):\n",
    "    model_output = (weights*3).sum()\n",
    "    \n",
    "    model_output.backward()\n",
    "    \n",
    "    print(weights.grad)\n",
    "    \n",
    "    weights.grad.zero_() # Empty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With optimization\n",
    "\n",
    "# optimizer = torch.optim.SGD(weights, lr=0.01)\n",
    "# optimizer.step()\n",
    "# optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa471c9",
   "metadata": {},
   "source": [
    "$\\Large\\text{Backpropagation}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "w = torch.tensor(1.0,requires_grad = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8069c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward pass and compute the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef602a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = w*x\n",
    "loss = (y_hat- y) **2\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97db7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "loss.backward()\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09d4cf5",
   "metadata": {},
   "source": [
    "$\\text{Next we have to update our weights and next forward and backkward}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3023e1",
   "metadata": {},
   "source": [
    "$\\Large\\text{Gradient Descent with Autograd and Backpropagation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a794b6e5",
   "metadata": {},
   "source": [
    "$\\text{Manually}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c4bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    \n",
    "    return w * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc17b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, y_pred):\n",
    "    \n",
    "    return ((y - y_pred)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE = 1/N * (w*x - y)**2\n",
    "#dJ/dw = 1/N 2x (w*x - y)\n",
    "\n",
    "def gradient(x,y, y_pred):\n",
    "    \n",
    "    return np.dot(2*x, y_pred - y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf89f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient(np.array([1,2,3]), np.array([2,4,8]), np.array([2,4,10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(np.array([2,4,8]), np.array([2,4,10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f552bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "n_iters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(range(1,5)), dtype = np.float32)\n",
    "Y = X.copy()*2\n",
    "w = 0.0\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    \n",
    "    # prediction = forward pass \n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    #loss \n",
    "    l = loss(Y,y_pred)\n",
    "    \n",
    "    #gradients\n",
    "    \n",
    "    dw = gradient(X,Y, y_pred)\n",
    "    \n",
    "    #update weights\n",
    "    \n",
    "    w = w - learning_rate*dw\n",
    "    \n",
    "    if epoch%1 == 0:\n",
    "        print(f'epoch {epoch + 1}: w = {w:.3f}, loss = {l:.8f}, dw = {dw}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bfa085",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb23b523",
   "metadata": {},
   "source": [
    "$\\text{Gradients computation with Autograd}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(list(range(1,5)), dtype = torch.float32)\n",
    "Y = X*2\n",
    "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True)\n",
    "n_iters = 20\n",
    "for epoch in range(n_iters):\n",
    "    \n",
    "    # prediction = forward pass \n",
    "    y_pred = forward(X)\n",
    "    #loss \n",
    "    l = loss(Y,y_pred)\n",
    "    \n",
    "    #gradients\n",
    "    \n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    #update weights\n",
    "    with torch.no_grad(): \n",
    "        w-= w.grad*learning_rate\n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "    if epoch%2 == 0:\n",
    "        print(f'epoch {epoch + 1}: w = {w:.3f}, loss = {l:.8f}, dw = {dw}')\n",
    "        \n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d005a0c",
   "metadata": {},
   "source": [
    "$\\text{Examples from the videos}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4faa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = np.zeros((7,7), dtype = np.int32)\n",
    "\n",
    "zero[1:-1, 2::3] = 1\n",
    "zero[1:-1:4, 2:-1] = 1\n",
    "\n",
    "\n",
    "plt.imshow(zero , cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70acee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = np.zeros((7,7), dtype = np.int32)\n",
    "one[1:-1,3] = 1\n",
    "plt.imshow(one , cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb8a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "two = np.zeros((7,7), dtype = np.int32)\n",
    "\n",
    "two[1:-1, 2] = 1\n",
    "two[1:-1:2, 2:-1] = 1\n",
    "two[2, 2] = 0\n",
    "two[2, -2] = 1\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(two , cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ba47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "three = np.zeros((7,7), dtype = np.int32)\n",
    "\n",
    "three[1:-1, -2] = 1\n",
    "three[1:-1:2, 1:-2] = 1\n",
    "\n",
    "plt.imshow(three , cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c782abed",
   "metadata": {},
   "outputs": [],
   "source": [
    "four = np.zeros((7,7), dtype = np.int32)\n",
    "\n",
    "four[1:4, 2:-1:3] = 1\n",
    "four[3, 2:-1] = 1\n",
    "four[3 :-1, -2] = 1\n",
    "# four[1:-1:2, 1:-2] = 1\n",
    "\n",
    "plt.imshow(four , cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c33d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "five = np.zeros((7,7), dtype = np.int32)\n",
    "\n",
    "five[1:-1, 2] = 1\n",
    "five[1:-1:2, 2:-1] = 1\n",
    "five[-3, -2] = 1\n",
    "five[-3, 2] = 0\n",
    "\n",
    "\n",
    "plt.imshow(five , cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5276bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "six = np.zeros((7,7), dtype = np.int32)\n",
    "\n",
    "six[1:-1, 2] = 1\n",
    "six[1:-1:2, 2:-1] = 1\n",
    "six[-3, -2] = 1\n",
    "\n",
    "# four[1:-1:2, 1:-2] = 1\n",
    "\n",
    "plt.imshow(six , cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30600dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sev = np.zeros((7,7), dtype = np.int32)\n",
    "\n",
    "sev[1:-1, -3] = 1\n",
    "sev[1, 2:-3] = 1\n",
    "\n",
    "# four[1:-1:2, 1:-2] = 1\n",
    "\n",
    "plt.imshow(sev , cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c6bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig = np.zeros((7,7), dtype = np.int32)\n",
    "\n",
    "eig[1:-1, 2::3] = 1\n",
    "eig[1:-1:2, 2:-1] = 1\n",
    "\n",
    "\n",
    "plt.imshow(eig , cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aeefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nine = np.zeros((7,7), dtype = np.int32)\n",
    "\n",
    "nine[1:-1, 2] = 1\n",
    "nine[1:-1:2, 2:-1] = 1\n",
    "nine[-3, -2] = 1\n",
    "nine[-3, 2] = 0\n",
    "nine[2, -2] = 1\n",
    "\n",
    "plt.imshow(nine , cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8875edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ac7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(t):\n",
    "    return np.maximum(t,0)\n",
    "\n",
    "def softmax(t):\n",
    "    \n",
    "    out = np.exp(t)\n",
    "    return out/np.sum(out)\n",
    "\n",
    "def sparse_cross_entropy(z,y):\n",
    "    return -np.log(z[0,y])\n",
    "\n",
    "\n",
    "def relu_deriv(t):\n",
    "    \n",
    "    return (t >= 0).astype(float)\n",
    "\n",
    "def predict(x):\n",
    "    if x.shape[0] != 1:\n",
    "        x = x.reshape(1,-1)\n",
    "    t1 = np.dot(x, W1) + b1\n",
    "    h1 = relu(t1)\n",
    "    t2 = h1 @ W2 + b2\n",
    "    z = softmax(t2)\n",
    "    return z\n",
    "\n",
    "def cals_accuracy(cur_set):\n",
    "    correct = 0\n",
    "    \n",
    "    for x,y in cur_set:\n",
    "        z = predict(x)\n",
    "        y_pred = np.argmax(z)\n",
    "        if y_pred == y:\n",
    "            correct += 1\n",
    "    acc = correct / len(cur_set)\n",
    "    return acc\n",
    "\n",
    "def to_full(y, num_classes):\n",
    "    y_full = np.zeros((1,num_classes))\n",
    "    \n",
    "    y_full[0,y] = 1\n",
    "    \n",
    "    return y_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07118c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.get('target').shape)\n",
    "print(iris.data[0].shape)\n",
    "print(iris.data[0][None, ...].shape) # [None, ...] from (4,) to (1, 4 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a89d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [(iris.data[i].reshape(1,-1), iris.target[i]) for i in range(len(iris.target))]\n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75446450",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 4\n",
    "out_dim = 3\n",
    "h_dim = 5\n",
    "epoch = 100\n",
    "batch_size = 50 # Hyperparameter\n",
    "\n",
    "W1 = np.random.randn(input_dim, h_dim)\n",
    "b1 = np.random.randn(1, h_dim)\n",
    "W2 = np.random.rand(h_dim, out_dim)\n",
    "b2 = np.random.randn(1, out_dim)\n",
    "\n",
    "# new initial values\n",
    "\n",
    "W1 = (W1 - 0.5)*2 * np.sqrt(1/input_dim)\n",
    "b1 = (b1 - 0.5)*2 * np.sqrt(1/input_dim)\n",
    "W2 = (W2 - 0.5)*2 * np.sqrt(1/h_dim)\n",
    "b2 = (b2 - 0.5)*2 * np.sqrt(1/h_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_arr = []\n",
    "acc = []\n",
    "for ep in range(epoch):\n",
    "    \n",
    "    random.shuffle(dataset)\n",
    "    for i in range(len(dataset)):\n",
    "\n",
    "        x,y = dataset[i]\n",
    "        #Forward \n",
    "\n",
    "        t1 = np.dot(x, W1) + b1\n",
    "        h1 = relu(t1)\n",
    "        t2 = h1 @ W2 + b2\n",
    "        z = softmax(t2)\n",
    "\n",
    "        E = sparse_cross_entropy(z,y)\n",
    "\n",
    "        #Backward\n",
    "\n",
    "        y_full = to_full(y, out_dim)\n",
    "        dE_dt2 = z - y_full \n",
    "        dE_dW2 = h1.T @ dE_dt2\n",
    "        dE_db2 = dE_dt2\n",
    "        dE_dh1 = dE_dt2 @W2.T\n",
    "        dE_dt1 = dE_dh1 * relu_deriv(t1)\n",
    "        dE_dW1 = x.T @ dE_dt1\n",
    "        dE_db1 = dE_dt1\n",
    "\n",
    "        alpha = 0.001\n",
    "\n",
    "        # update \n",
    "\n",
    "        W1 = W1 - alpha * dE_dW1\n",
    "        b1 = b1 - alpha * dE_db1\n",
    "        W2 = W2 - alpha * dE_dW2\n",
    "        b2 = b2 - alpha * dE_db2\n",
    "        \n",
    "        loss_arr.append(E)\n",
    "#         acc.append(cals_accuracy(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8601446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd58203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_batch(t):\n",
    "    \n",
    "    out = np.exp(t)\n",
    "    return out/np.sum(out, axis = 1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cross_entropy_batch(z,y):\n",
    "    \n",
    "    return - np.log(np.array([z[j, y[j]] for j in range(len(y))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67419d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_full_batch(y, num_classes):\n",
    "    y_full = np.zeros((len(y), num_classes))\n",
    "    \n",
    "    for j, yj in enumerate(y):\n",
    "        y_full[j,yj] = 1\n",
    "        \n",
    "    return y_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d2325",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_arr = []\n",
    "arr = []\n",
    "for ep in range(500):\n",
    "    \n",
    "    random.shuffle(dataset)\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        \n",
    "        batch_x, batch_y = zip(*dataset[i*batch_size: (i+1)*batch_size])\n",
    "        x = np.concatenate(batch_x, axis = 0)\n",
    "        y = np.array(batch_y)\n",
    "        #Forward \n",
    "\n",
    "        t1 = np.dot(x, W1) + b1\n",
    "        h1 = relu(t1)\n",
    "        t2 = h1 @ W2 + b2\n",
    "        z = softmax_batch(t2)\n",
    "\n",
    "        E = np.sum(sparse_cross_entropy_batch(z,y))\n",
    "\n",
    "        #Backward\n",
    "\n",
    "        y_full = to_full_batch(y, out_dim)\n",
    "        \n",
    "        dE_dt2 = z - y_full \n",
    "        dE_dW2 = h1.T @ dE_dt2\n",
    "        \n",
    "        dE_db2 = np.sum(dE_dt2, axis = 0, keepdims = True)\n",
    "        dE_dh1 = dE_dt2 @W2.T\n",
    "        dE_dt1 = dE_dh1 * relu_deriv(t1)\n",
    "        dE_dW1 = x.T @ dE_dt1\n",
    "        dE_db1 = np.sum(dE_dt1, axis = 0, keepdims = True)\n",
    "\n",
    "        alpha = 0.001\n",
    "\n",
    "        # update \n",
    "\n",
    "        W1 = W1 - alpha * dE_dW1\n",
    "        b1 = b1 - alpha * dE_db1\n",
    "        W2 = W2 - alpha * dE_dW2\n",
    "        b2 = b2 - alpha * dE_db2\n",
    "        \n",
    "        loss_arr.append(E)\n",
    "        acc.append(cals_accuracy(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8198cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f901e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85265ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e986c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr0 = np.zeros(10, dtype = np.int32)\n",
    "curr1 = np.zeros(10, dtype = np.int32)\n",
    "curr2 = np.zeros(10, dtype = np.int32)\n",
    "curr3 = np.zeros(10, dtype = np.int32)\n",
    "curr4 = np.zeros(10, dtype = np.int32)\n",
    "curr5 = np.zeros(10, dtype = np.int32)\n",
    "curr6 = np.zeros(10, dtype = np.int32)\n",
    "curr7 = np.zeros(10, dtype = np.int32)\n",
    "curr8 = np.zeros(10, dtype = np.int32)\n",
    "curr9 = np.zeros(10, dtype = np.int32)\n",
    "\n",
    "curr0[0] = 1\n",
    "curr1[1] = 1\n",
    "curr2[2] = 1\n",
    "curr3[3] = 1\n",
    "curr4[4] = 1\n",
    "curr5[5] = 1\n",
    "curr6[6] = 1\n",
    "curr7[7] = 1\n",
    "curr8[8] = 1\n",
    "curr9[9] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1326127",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = {\n",
    "    0:[zero, curr0],\n",
    "    1:[one,curr1],\n",
    "    2:[two,curr2],\n",
    "    3:[three,curr3],\n",
    "    4:[four,curr4],\n",
    "    5:[five,curr5],\n",
    "    6:[six,curr6],\n",
    "    7:[sev,curr7],\n",
    "    8:[eig,curr8],\n",
    "    9:[nine,curr9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c27133",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.maximum([1,-2,3], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba9315",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 49\n",
    "\n",
    "h_dim = 10\n",
    "\n",
    "out_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd2536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dts = list(digits.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6935bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 49\n",
    "h_dim = 20\n",
    "out_dim = 10\n",
    "W1 = np.random.randn(input_dim, h_dim)\n",
    "b1 = np.random.randn(1, h_dim)\n",
    "W2 = np.random.rand(h_dim, out_dim)\n",
    "b2 = np.random.randn(1, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f7d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_arr = []\n",
    "arr = []\n",
    "for ep in range(epoch):\n",
    "    \n",
    "    random.shuffle(dts)\n",
    "    for i in range(len(dts)):\n",
    "\n",
    "        x,y = dts[i]\n",
    "        x = x.ravel().reshape(1,-1).copy()\n",
    "        y = y.reshape(1,-1).copy()\n",
    "        #Forward \n",
    "\n",
    "        t1 = np.dot(x, W1) + b1\n",
    "        h1 = relu(t1)\n",
    "        t2 = h1 @ W2 + b2\n",
    "        z = softmax(t2)\n",
    "\n",
    "        E = sparse_cross_entropy(z,np.argmax(y))\n",
    "\n",
    "        #Backward\n",
    "\n",
    "        y_full = y.copy()\n",
    "        dE_dt2 = z - y_full \n",
    "        dE_dW2 = h1.T @ dE_dt2\n",
    "        dE_db2 = dE_dt2\n",
    "        dE_dh1 = dE_dt2 @W2.T\n",
    "        dE_dt1 = dE_dh1 * relu_deriv(t1)\n",
    "        dE_dW1 = x.T @ dE_dt1\n",
    "        dE_db1 = dE_dt1\n",
    "\n",
    "        alpha = 0.001\n",
    "\n",
    "        # update \n",
    "\n",
    "        W1 = W1 - alpha * dE_dW1\n",
    "        b1 = b1 - alpha * dE_db1\n",
    "        W2 = W2 - alpha * dE_dW2\n",
    "        b2 = b2 - alpha * dE_db2\n",
    "        \n",
    "        loss_arr.append(E)\n",
    "        y = np.argmax(y)\n",
    "#         acc.append(cals_accuracy(dts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fda083",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 3\n",
    "plt.imshow(dts[num][0], cmap = 'binary')\n",
    "print(f'Predicted value - {np.argmax(predict(dts[num][0]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a030dc32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "addd7d4d",
   "metadata": {},
   "source": [
    "$\\text{Gradiens computation: Autograd, Loss computation: PyTorch Loss, Parameter updates: PyTorch Optimizer}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Design model (input size, output size, forward pass )\n",
    "# 2) Construct loss and optimizer\n",
    "# 3) Training loop\n",
    "\n",
    "# - forward pass: compute prediction\n",
    "# - backward pass: gradients\n",
    "# - update weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d38d22da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af76070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    \n",
    "    return w * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "759c8273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 21: w = 1.934, loss = 0.04506890\n",
      "epoch 31: w = 1.987, loss = 0.00174685\n",
      "epoch 41: w = 1.997, loss = 0.00006770\n",
      "epoch 51: w = 1.999, loss = 0.00000262\n",
      "epoch 61: w = 2.000, loss = 0.00000010\n",
      "epoch 71: w = 2.000, loss = 0.00000000\n",
      "epoch 81: w = 2.000, loss = 0.00000000\n",
      "epoch 91: w = 2.000, loss = 0.00000000\n",
      "Prediction before training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(list(range(1,5)), dtype = torch.float32)\n",
    "Y = torch.tensor(list(range(1,5)), dtype = torch.float32)*2\n",
    "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True)\n",
    "n_iters = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr = learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    \n",
    "    # prediction = forward pass \n",
    "    y_pred = forward(X)\n",
    "    #loss \n",
    "    l = loss(Y,y_pred)\n",
    "    \n",
    "    #gradients\n",
    "    \n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    if epoch%10 == 0:\n",
    "        print(f'epoch {epoch + 1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "        \n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ffec5bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = -2.396\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(-1,1)\n",
    "Y = Y.reshape(-1,1)\n",
    "n_iters = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "n_samples, n_feature = X.shape\n",
    "\n",
    "input_size = n_feature\n",
    "output_size = n_feature\n",
    "\n",
    "X_test = torch.tensor([5], dtype = torch.float32)\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08c8565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: w = -0.094, loss = 46.41172028\n",
      "epoch 100: w = 1.825, loss = 0.04440691\n",
      "epoch 200: w = 1.870, loss = 0.02437883\n",
      "epoch 300: w = 1.904, loss = 0.01338367\n",
      "epoch 400: w = 1.929, loss = 0.00734748\n",
      "epoch 500: w = 1.947, loss = 0.00403367\n",
      "epoch 600: w = 1.961, loss = 0.00221444\n",
      "epoch 700: w = 1.971, loss = 0.00121571\n",
      "epoch 800: w = 1.979, loss = 0.00066740\n",
      "epoch 900: w = 1.984, loss = 0.00036640\n",
      "Prediction before training: f(5) = 9.976\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_iters):\n",
    "    \n",
    "    # prediction = forward pass \n",
    "    y_pred = model(X)\n",
    "    #loss \n",
    "    l = loss(Y,y_pred)\n",
    "    \n",
    "    #gradients\n",
    "    \n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    if epoch%100 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f'epoch {epoch}: w = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
    "        \n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfac8770",
   "metadata": {},
   "source": [
    "$\\text{Let's write our own model}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4ea93b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, out_dim):\n",
    "        super().__init__()\n",
    "        #define layers\n",
    "        \n",
    "        self.lin = nn.Linear(input_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.lin(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89a0db7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = -2.991\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(-1,1)\n",
    "Y = Y.reshape(-1,1)\n",
    "n_iters = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "n_samples, n_feature = X.shape\n",
    "\n",
    "input_size = n_feature\n",
    "output_size = n_feature\n",
    "\n",
    "X_test = torch.tensor([5], dtype = torch.float32)\n",
    "\n",
    "# model = nn.Linear(input_size, output_size)\n",
    "model = LinearRegression(input_size, output_size)\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5e6e8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: w = -0.241, loss = 49.87801361\n",
      "epoch 100: w = 1.766, loss = 0.07958636\n",
      "epoch 200: w = 1.827, loss = 0.04369196\n",
      "epoch 300: w = 1.871, loss = 0.02398637\n",
      "epoch 400: w = 1.905, loss = 0.01316821\n",
      "epoch 500: w = 1.929, loss = 0.00722919\n",
      "epoch 600: w = 1.948, loss = 0.00396873\n",
      "epoch 700: w = 1.961, loss = 0.00217879\n",
      "epoch 800: w = 1.971, loss = 0.00119612\n",
      "epoch 900: w = 1.979, loss = 0.00065665\n",
      "Prediction before training: f(5) = 9.967\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_iters):\n",
    "    \n",
    "    # prediction = forward pass \n",
    "    y_pred = model(X)\n",
    "    #loss \n",
    "    l = loss(Y,y_pred)\n",
    "    \n",
    "    #gradients\n",
    "    \n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    if epoch%100 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f'epoch {epoch}: w = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
    "        \n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aad7204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99b97aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0) prepare data\n",
    "\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples = 100, n_features=1, noise=20, random_state=1)\n",
    "\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "\n",
    "y = y.view(y.shape[0], 1) #reshape tensor\n",
    "\n",
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db575ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Model\n",
    "\n",
    "input_size = n_features\n",
    "output_size = 1 # We want to have one value for each sample that we want to put in\n",
    "model = nn.Linear(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cbf01953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2)Loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "244f9840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 502.1649\n",
      "epoch: 20, loss = 456.3393\n",
      "epoch: 30, loss = 422.9299\n",
      "epoch: 40, loss = 398.5614\n",
      "epoch: 50, loss = 380.7797\n",
      "epoch: 60, loss = 367.7990\n",
      "epoch: 70, loss = 358.3199\n",
      "epoch: 80, loss = 351.3958\n",
      "epoch: 90, loss = 346.3363\n",
      "epoch: 100, loss = 342.6384\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3) training loop\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for ep in range(n_epochs):\n",
    "    \n",
    "    #forward pass and loss\n",
    "    y_pred = model(X)\n",
    "    loss = criterion(y_pred, y)\n",
    "    #backward \n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    #update\n",
    "    \n",
    "    optimizer.step() #update the weights\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (ep+1) % 10 == 0:\n",
    "        \n",
    "        print(f'epoch: {ep+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "predicted = model(X).detach().numpy()  # detach() generate new tensor where our attribute required_grad is false\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d6534728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e171e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 30\n"
     ]
    }
   ],
   "source": [
    "#0) prepare data\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X,y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 1234)\n",
    "\n",
    "# scale \n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74a80177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Model\n",
    "# f = wx+b, sigmoid at the end\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        \n",
    "        return y_predicted\n",
    "    \n",
    "model = LogisticRegression(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2a24cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) loss and optimizer \n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9624df5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, loss = 0.2306\n",
      "epoch: 200, loss = 0.1691\n",
      "epoch: 300, loss = 0.1419\n",
      "epoch: 400, loss = 0.1256\n",
      "epoch: 500, loss = 0.1146\n",
      "epoch: 600, loss = 0.1064\n",
      "epoch: 700, loss = 0.1001\n",
      "epoch: 800, loss = 0.0951\n",
      "epoch: 900, loss = 0.0909\n",
      "epoch: 1000, loss = 0.0873\n",
      "accuracy = 0.9474\n"
     ]
    }
   ],
   "source": [
    "#3) training loop\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass and loss \n",
    "    \n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "    \n",
    "    # backward pass \n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    # updates\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1)  % 100 ==0:\n",
    "        \n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy = {acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1207e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a09ad4d",
   "metadata": {},
   "source": [
    "$\\Large\\text{Dataset and DataLoader - Batch Training}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41e94a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68188f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation of our own dataset\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #data loading\n",
    "        xy = np.loadtxt('wine.csv', delimiter=',', dtype = np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:,1:])\n",
    "        self.y = torch.from_numpy(xy[:,[0]]) #n_samples = 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        # dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):  # is used to len(dataset)\n",
    "        return self.n_samples\n",
    "        #len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9287f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "dataset = WineDataset()\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle = True) # num_workers=2 we can add \n",
    "# first_data = dataset[0]\n",
    "# features, labels = first_data\n",
    "# features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6614fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle = True) # num_workers=2 we can add \n",
    "# dataiter = iter(dataloader)\n",
    "# data = next(dataiter)\n",
    "# features, labels = data\n",
    "# features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eac51b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples / batch_size)\n",
    "print(total_samples,n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "208b768d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 45/45, inputs torch.Size([2, 13])\n",
      "epoch 2/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 45/45, inputs torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        # forward backward update\n",
    "        \n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33151c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.datasets.MNIST() built-in datasets\n",
    "#fashion-mnist , cifar, coco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02299434",
   "metadata": {},
   "source": [
    "$\\Large\\text{Dataset Transforms}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9f8b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation of our own dataset\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transform = None):\n",
    "        \n",
    "        #data loading\n",
    "        xy = np.loadtxt('wine.csv', delimiter=',', dtype = np.float32, skiprows=1)\n",
    "#         self.x = torch.from_numpy(xy[:,1:])\n",
    "#         self.y = torch.from_numpy(xy[:,[0]]) #n_samples = 1\n",
    "        \n",
    "        self.x = xy[:,1:]\n",
    "        self.y = xy[:,[0]]\n",
    "    \n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        # dataset[0]\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "        \n",
    "    def __len__(self):  # is used to len(dataset)\n",
    "        return self.n_samples\n",
    "        #len(dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78edc74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        \n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "925d53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulTransform:\n",
    "    \n",
    "    def __init__(self,factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        inputs, target = sample\n",
    "        \n",
    "        inputs *= self.factor\n",
    "        \n",
    "        return inputs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d70b9ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = WineDataset(transform=ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ac20898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
       "         6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
       "         2.1300e+03]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compose transform\n",
    "\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
    "dataset = WineDataset(transform = composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0440bb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "# torch softmax \n",
    "\n",
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim = 0)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc3a74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20a0b96f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4676,  0.6266,  1.4435],\n",
       "         [-2.5441, -0.9679, -0.8555]]),\n",
       " tensor([[0.2072, 0.2429, 0.5498],\n",
       "         [0.0889, 0.4300, 0.4811]]),\n",
       " tensor([1.0000, 1.0000]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, output, output.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2c7b1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=0)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cc2906b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4699, -0.1472, -0.1219],\n",
       "         [ 0.7588,  0.2747,  0.4442]]),\n",
       " tensor([[0.4283, 0.3961, 0.3621],\n",
       "         [0.5717, 0.6039, 0.6379]]),\n",
       " tensor([1.0000, 1.0000, 1.0000]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, output, output.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f6317c9e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def cross_entropy(actual, predicted):\n",
    "    loss = - np.sum(actual * np.log(predicted))\n",
    "    return loss # ideally normalize it like / float(predicted.shape[0])\n",
    "\n",
    "# y must be one hot encoded \n",
    "# if class 0: [1, 0, 0]\n",
    "# if class 1: [0, 1, 0]\n",
    "# if class 2: [0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "88ca656b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4170299470424652 1.840616226196289\n",
      "tensor([0]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([0]) # No hot encoded\n",
    "# size: n_samples * n_classes = 1 * 3\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]]) #raw values\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]]) #raw values\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(l1.item(), l2.item())\n",
    "\n",
    "\n",
    "_, predictions1 = torch.max(Y_pred_good,1)\n",
    "_, predictions2 = torch.max(Y_pred_bad,1)\n",
    "print(predictions1,predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a0ea991b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3002483546733856 1.6225852966308594\n",
      "tensor([2, 0, 1]) tensor([0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "# 3 samples\n",
    "Y = torch.tensor([2,0,1]) # No hot encoded  right classes\n",
    "# size: n_samples * n_classes = 3 * 3\n",
    "Y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [2.0, 1.0, 0.1],[0.0, 3.0, 0.1]]) #raw values\n",
    "Y_pred_bad = torch.tensor([[2.1, 1.0, 0.1], [0.1, 1.0, 2.1],[0.0, 3.0, 0.1]]) #raw values\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(l1.item(), l2.item())\n",
    "\n",
    "\n",
    "_, predictions1 = torch.max(Y_pred_good,1)\n",
    "_, predictions2 = torch.max(Y_pred_bad,1)\n",
    "print(predictions1,predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "45bdd6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "82f044f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet2(input_size = 28*28, hidden_size = 5, num_classes=3)\n",
    "criterion = nn.CrossEntropyLoss() # applies Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1404b670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceedfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a22ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f603e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
