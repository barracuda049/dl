{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e1a4df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision \n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d076a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for a device \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50bf695a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00a50d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform\n",
    "\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5, 0.5], #0-1 to [-1,1], formula (x-mean)/std\n",
    "                        [0.5,0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98ff7165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader\n",
    "train_path = 'D:\\hppl\\seg_train/seg_train'\n",
    "test_path = 'D:\\hppl\\seg_test/seg_test'\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path, transform=transformer),\n",
    "    batch_size = 256, shuffle=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path, transform=transformer),\n",
    "    batch_size = 256, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b623652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#categories\n",
    "root = pathlib.Path(train_path)\n",
    "classes = sorted([j.name for j in root.iterdir()])\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22fbcb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Network\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        \n",
    "        #Input image = (256(Batch size), 3(RGB), 150,150)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3,stride=1, padding=1)\n",
    "        #Shape (256, 12,150,150)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "        #Shape (256, 12,150,150)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        #Shape (256, 12,150,150)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape (256, 12,75,75)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3,stride=1, padding=1)\n",
    "        #Shape (256, 20,75,75)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        #Shape (256, 12,150,150)\n",
    "        \n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3,stride=1, padding=1)\n",
    "        #Shape (256, 32,75,75)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        #Shape (256, 32,75,75)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        #Shape (256, 32,75,75)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features = 32*75*75, out_features = num_classes)\n",
    "        \n",
    "    def forward(self,input):\n",
    "\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "\n",
    "        output = self.pool(output)\n",
    "\n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "\n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "\n",
    "        #Above output will be in matrix form, with shape (256, 32,75,75)\n",
    "\n",
    "        output = output.view(-1, 32*75*75)\n",
    "\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4969687",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes=6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c39f4ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr = 0.001, weight_decay=0.00001)\n",
    "loss_function= nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf6407d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e741176a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14034, 3000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the size of training and testing images\n",
    "train_count = len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count = len(glob.glob(test_path+'/**/*.jpg'))\n",
    "train_count,test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19997de2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 7 Train Accuracy: 0.06398745902807468 Test Accuracy: 0.37866666666666665\n",
      "Epoch: 1 Train Loss: 2 Train Accuracy: 0.10146786375944136 Test Accuracy: 0.22866666666666666\n",
      "Epoch: 2 Train Loss: 1 Train Accuracy: 0.12355707567336469 Test Accuracy: 0.32266666666666666\n",
      "Epoch: 3 Train Loss: 0 Train Accuracy: 0.1417984893829272 Test Accuracy: 0.542\n",
      "Epoch: 4 Train Loss: 0 Train Accuracy: 0.16132250249394328 Test Accuracy: 0.5753333333333334\n",
      "Epoch: 5 Train Loss: 0 Train Accuracy: 0.17799629471284026 Test Accuracy: 0.8233333333333334\n",
      "Epoch: 6 Train Loss: 0 Train Accuracy: 0.19295995439646574 Test Accuracy: 0.931\n",
      "Epoch: 7 Train Loss: 0 Train Accuracy: 0.1956676642439789 Test Accuracy: 0.923\n",
      "Epoch: 8 Train Loss: 0 Train Accuracy: 0.2003705287159755 Test Accuracy: 0.9406666666666667\n",
      "Epoch: 9 Train Loss: 0 Train Accuracy: 0.20485962662106313 Test Accuracy: 0.973\n"
     ]
    }
   ],
   "source": [
    "#Model training and saving best models\n",
    "\n",
    "\n",
    "\n",
    "best_accuracy =0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss =0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=loss.cpu().data*images.size(0)\n",
    "        _,prediction = torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+= int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    #Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    test_accuracy = test_accuracy/test_count\n",
    "    \n",
    "    \n",
    "    print(f'Epoch: {epoch} Train Loss: {int(train_loss)} Train Accuracy: {train_accuracy} Test Accuracy: {test_accuracy}')\n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_checkpoint.model')\n",
    "        \n",
    "        best_accuracy = test_accuracy\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262e2f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self,first_name):\n",
    "        self.first_name = first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9eca79ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(A):\n",
    "    def __init__(self, first_name, last):\n",
    "        super(B, self).__init__(first_name)\n",
    "        self.last = last\n",
    "        print(f'{first_name} {last}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ed95530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A B\n"
     ]
    }
   ],
   "source": [
    "a = B('A', 'B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72593229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
