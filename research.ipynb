{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUhMBvHevzu2"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import time \n",
    "import os\n",
    "from google.colab import drive\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzCuvR7FQt-a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision \n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torchvision.transforms import functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWl4SRT9Cx8z",
    "outputId": "61cef478-569a-4b27-c440-266832c14a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
      "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.1+cu116)\n",
      "Installing collected packages: torchmetrics\n",
      "Successfully installed torchmetrics-0.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kNuybHgC5vo"
   },
   "outputs": [],
   "source": [
    "from torchmetrics import JaccardIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PS6jiagiv3VC",
    "outputId": "fe8cc9a5-aacf-4b9b-fec6-5bf4558ec810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F57taM7NwISz"
   },
   "outputs": [],
   "source": [
    "!ls /content/drive/MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjEgpnQmEwRd"
   },
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/TOP4040.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-DJwbbiwW-K"
   },
   "outputs": [],
   "source": [
    "zip_file = '/content/drive/MyDrive/TOP4040.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9BNZ-TyR-eZb",
    "outputId": "8734a73d-0193-4e4a-a4ef-6c76f3a94fbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9983"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('TOP4040/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sPzPRYpQ9y0"
   },
   "outputs": [],
   "source": [
    "path = 'TOP4040/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aP-z5mItsMgd"
   },
   "outputs": [],
   "source": [
    "class ToPIL:\n",
    "    def __init__(self):\n",
    "        self.for_image = transforms.ToPILImage(mode = 'LA')\n",
    "        self.for_target = transforms.ToPILImage(mode = 'L')\n",
    "    def __call__(self,sample):\n",
    "        image, target = sample\n",
    "        return self.for_image(image), self.for_target(target)\n",
    "    \n",
    "class FromPILToTensor:\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        image, target = sample\n",
    "        \n",
    "        return TF.pil_to_tensor(image)/255 , TF.pil_to_tensor(target)/255\n",
    "    \n",
    "class RandomHorizontalFlip:\n",
    "    def __init__(self, prob):\n",
    "        self.prob = prob\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, target = sample\n",
    "        \n",
    "        if random.random() < self.prob:\n",
    "            \n",
    "            image = TF.hflip(image)\n",
    "            target = TF.hflip(target)\n",
    "        return image, target\n",
    "    \n",
    "class Compose:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __call__(self,sample):\n",
    "        image, target = sample\n",
    "        \n",
    "        for t in self.transform:\n",
    "            sample = t(sample)\n",
    "        return sample\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        image, target = sample\n",
    "        \n",
    "        return torch.from_numpy(image.astype(np.float32)), torch.from_numpy(target.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIz5vYKpQa-_"
   },
   "outputs": [],
   "source": [
    "class NPZLoader(Dataset):\n",
    "    def __init__(self, path, transform=None, cur_iter = 7, target = -1):\n",
    "        self.path = path\n",
    "        self.files = list(Path(path).glob('**/*.npz'))\n",
    "        self.transform = transform\n",
    "        self.cur_iter = cur_iter\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        numpy_array = np.load(self.files[item])['arr_0']\n",
    "        target = (numpy_array[self.target] > 0.5).astype(np.float32)\n",
    "        r,c = numpy_array[0].shape\n",
    "        n_1_iter = numpy_array[self.cur_iter]\n",
    "        n_iter = numpy_array[self.cur_iter-1]\n",
    "        gradient = (n_1_iter - n_iter).reshape(1,r,c)\n",
    "        sample = np.concatenate((n_1_iter.reshape(1,r,c),gradient)), target.reshape(1,40,40)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6AoHX3NJQz0j"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "''' inplace=True means that \n",
    "                it will modify the input \n",
    "                directly, without allocating any\n",
    "                additional output. It can sometimes slightly decrease the memory usage\n",
    "'''\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels,kernel_size=3,stride = 1,padding = 1, bias =False), # bias false cause we use batch norm\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels,kernel_size=3,stride = 1,padding = 1, bias =False), # bias false cause we use batch norm\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "\n",
    "class UNET(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels = 3, out_channels = 1, features = [64,128,256,512] # features - the channels\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.drop = nn.Dropout()\n",
    "\n",
    "        #Down part of UNET\n",
    "\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # up part of UNET\n",
    "\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(feature *2, feature, kernel_size=2, stride = 2)\n",
    "            )\n",
    "\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "           \n",
    "    def forward(self,x):\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        x = self.drop(self.bottleneck(x))\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x) # ConvTranspose2d\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, size = skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection,x), dim = 1) # concatenate and the double conv\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        return self.sig(self.final_conv(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vuTAaxm-RFRO"
   },
   "outputs": [],
   "source": [
    "check = NPZLoader(path,cur_iter = 50, transform = ToTensor(), target = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "Z3iBV8UcRMB7",
    "outputId": "02b3f63b-925e-4fb1-b735-4b4218df4f31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc61074cca0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x792 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = 55\n",
    "plt.figure(figsize = (14,11))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(f'Target')\n",
    "plt.imshow(TF.hflip(check[num][1][0]), cmap= 'binary')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(f'n_iters = {check.cur_iter}')\n",
    "plt.imshow(TF.vflip(check[num][0][0]), cmap= 'binary')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(f'gradient')\n",
    "plt.imshow(check[num][0][1], cmap= 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JObw_zRqi0W9"
   },
   "outputs": [],
   "source": [
    "train_set = []\n",
    "test_set = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-x6kKqCgipCf"
   },
   "outputs": [],
   "source": [
    "for i in range(int(0.8*len(check))):\n",
    "  try:\n",
    "    train_set.append(check[i])\n",
    "  except:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uN62HwwRj3cZ"
   },
   "outputs": [],
   "source": [
    "for i in range(int(0.8*len(check)), len(check)):\n",
    "  try:\n",
    "    test_set.append(check[i])\n",
    "  except:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WB-Bl4FmR_QU",
    "outputId": "8393d858-217d-4ee1-88a6-9062f2059d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7985\n",
      "1996\n",
      "9981\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(len(train_set) + len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-CvxDEPowEb"
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_set)):\n",
    "    if random.random() > 0.2:\n",
    "        train_set.append((\n",
    "            torch.from_numpy(np.concatenate(\n",
    "                (train_set[i][0][0].T.view(1,40,40), train_set[i][0][1].T.view(1,40,40))\n",
    "            )), train_set[i][1].view(40,40).T.view(1,40,40)\n",
    "        )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pSHiLPwicU9"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set, batch_size=100, shuffle = True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=100, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UefgF8TGnfUr"
   },
   "outputs": [],
   "source": [
    "features = [128,256,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78Rudwi9Yo7p"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRseGmROniNx"
   },
   "outputs": [],
   "source": [
    "model = UNET(in_channels = 2, out_channels=1, features=features).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "D6GeImP7kxYW",
    "outputId": "958c9403-094e-49ca-8bfe-1013abe9520e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "epoch 1 / 100, step 1/145, loss = 1.045101\n",
      "epoch 1 / 100, step 2/145, loss = 1.032368\n",
      "epoch 1 / 100, step 3/145, loss = 1.041106\n",
      "epoch 1 / 100, step 4/145, loss = 1.034771\n",
      "epoch 1 / 100, step 5/145, loss = 1.037130\n",
      "epoch 1 / 100, step 6/145, loss = 1.042236\n",
      "epoch 1 / 100, step 7/145, loss = 1.031811\n",
      "epoch 1 / 100, step 8/145, loss = 1.031056\n",
      "epoch 1 / 100, step 9/145, loss = 1.045372\n",
      "epoch 1 / 100, step 10/145, loss = 1.044556\n",
      "epoch 1 / 100, step 11/145, loss = 1.040291\n",
      "epoch 1 / 100, step 12/145, loss = 1.031210\n",
      "epoch 1 / 100, step 13/145, loss = 1.035430\n",
      "epoch 1 / 100, step 14/145, loss = 1.033798\n",
      "epoch 1 / 100, step 15/145, loss = 1.022149\n",
      "epoch 1 / 100, step 16/145, loss = 1.041369\n",
      "epoch 1 / 100, step 17/145, loss = 1.036180\n",
      "epoch 1 / 100, step 18/145, loss = 1.042406\n",
      "epoch 1 / 100, step 19/145, loss = 1.040468\n",
      "epoch 1 / 100, step 20/145, loss = 1.039768\n",
      "epoch 1 / 100, step 21/145, loss = 1.037549\n",
      "epoch 1 / 100, step 22/145, loss = 1.029146\n",
      "epoch 1 / 100, step 23/145, loss = 1.049178\n",
      "epoch 1 / 100, step 24/145, loss = 1.044879\n",
      "epoch 1 / 100, step 25/145, loss = 1.035077\n",
      "epoch 1 / 100, step 26/145, loss = 1.030938\n",
      "epoch 1 / 100, step 27/145, loss = 1.035798\n",
      "epoch 1 / 100, step 28/145, loss = 1.039829\n",
      "epoch 1 / 100, step 29/145, loss = 1.040002\n",
      "epoch 1 / 100, step 30/145, loss = 1.045422\n",
      "epoch 1 / 100, step 31/145, loss = 1.023645\n",
      "epoch 1 / 100, step 32/145, loss = 1.039258\n",
      "epoch 1 / 100, step 33/145, loss = 1.033391\n",
      "epoch 1 / 100, step 34/145, loss = 1.039508\n",
      "epoch 1 / 100, step 35/145, loss = 1.033964\n",
      "epoch 1 / 100, step 36/145, loss = 1.034722\n",
      "epoch 1 / 100, step 37/145, loss = 1.032456\n",
      "epoch 1 / 100, step 38/145, loss = 1.050250\n",
      "epoch 1 / 100, step 39/145, loss = 1.036679\n",
      "epoch 1 / 100, step 40/145, loss = 1.025844\n",
      "epoch 1 / 100, step 41/145, loss = 1.028611\n",
      "epoch 1 / 100, step 42/145, loss = 1.037461\n",
      "epoch 1 / 100, step 43/145, loss = 1.044231\n",
      "epoch 1 / 100, step 44/145, loss = 1.031869\n",
      "epoch 1 / 100, step 45/145, loss = 1.030182\n",
      "epoch 1 / 100, step 46/145, loss = 1.037273\n",
      "epoch 1 / 100, step 47/145, loss = 1.038245\n",
      "epoch 1 / 100, step 48/145, loss = 1.043345\n",
      "epoch 1 / 100, step 49/145, loss = 1.040419\n",
      "epoch 1 / 100, step 50/145, loss = 1.041557\n",
      "epoch 1 / 100, step 51/145, loss = 1.043125\n",
      "epoch 1 / 100, step 52/145, loss = 1.027822\n",
      "epoch 1 / 100, step 53/145, loss = 1.029171\n",
      "epoch 1 / 100, step 54/145, loss = 1.034570\n",
      "epoch 1 / 100, step 55/145, loss = 1.043946\n",
      "epoch 1 / 100, step 56/145, loss = 1.043267\n",
      "epoch 1 / 100, step 57/145, loss = 1.044529\n",
      "epoch 1 / 100, step 58/145, loss = 1.037532\n",
      "epoch 1 / 100, step 59/145, loss = 1.022677\n",
      "epoch 1 / 100, step 60/145, loss = 1.033811\n",
      "epoch 1 / 100, step 61/145, loss = 1.046694\n",
      "epoch 1 / 100, step 62/145, loss = 1.035864\n",
      "epoch 1 / 100, step 63/145, loss = 1.044732\n",
      "epoch 1 / 100, step 64/145, loss = 1.042050\n",
      "epoch 1 / 100, step 65/145, loss = 1.037657\n",
      "epoch 1 / 100, step 66/145, loss = 1.037071\n",
      "epoch 1 / 100, step 67/145, loss = 1.034796\n",
      "epoch 1 / 100, step 68/145, loss = 1.043942\n",
      "epoch 1 / 100, step 69/145, loss = 1.034435\n",
      "epoch 1 / 100, step 70/145, loss = 1.039043\n",
      "epoch 1 / 100, step 71/145, loss = 1.038118\n",
      "epoch 1 / 100, step 72/145, loss = 1.046068\n",
      "epoch 1 / 100, step 73/145, loss = 1.040938\n",
      "epoch 1 / 100, step 74/145, loss = 1.039445\n",
      "epoch 1 / 100, step 75/145, loss = 1.034874\n",
      "epoch 1 / 100, step 76/145, loss = 1.039779\n",
      "epoch 1 / 100, step 77/145, loss = 1.038840\n",
      "epoch 1 / 100, step 78/145, loss = 1.026604\n",
      "epoch 1 / 100, step 79/145, loss = 1.030475\n",
      "epoch 1 / 100, step 80/145, loss = 1.033674\n",
      "epoch 1 / 100, step 81/145, loss = 1.043113\n",
      "epoch 1 / 100, step 82/145, loss = 1.034759\n",
      "epoch 1 / 100, step 83/145, loss = 1.042982\n",
      "epoch 1 / 100, step 84/145, loss = 1.040275\n",
      "epoch 1 / 100, step 85/145, loss = 1.037576\n",
      "epoch 1 / 100, step 86/145, loss = 1.034581\n",
      "epoch 1 / 100, step 87/145, loss = 1.036663\n",
      "epoch 1 / 100, step 88/145, loss = 1.030039\n",
      "epoch 1 / 100, step 89/145, loss = 1.037538\n",
      "epoch 1 / 100, step 90/145, loss = 1.040967\n",
      "epoch 1 / 100, step 91/145, loss = 1.038977\n",
      "epoch 1 / 100, step 92/145, loss = 1.040298\n",
      "epoch 1 / 100, step 93/145, loss = 1.031895\n",
      "epoch 1 / 100, step 94/145, loss = 1.029461\n",
      "epoch 1 / 100, step 95/145, loss = 1.037309\n",
      "epoch 1 / 100, step 96/145, loss = 1.030970\n",
      "epoch 1 / 100, step 97/145, loss = 1.034621\n",
      "epoch 1 / 100, step 98/145, loss = 1.043432\n",
      "epoch 1 / 100, step 99/145, loss = 1.035604\n",
      "epoch 1 / 100, step 100/145, loss = 1.029544\n",
      "epoch 1 / 100, step 101/145, loss = 1.045112\n",
      "epoch 1 / 100, step 102/145, loss = 1.048385\n",
      "epoch 1 / 100, step 103/145, loss = 1.041387\n",
      "epoch 1 / 100, step 104/145, loss = 1.034262\n",
      "epoch 1 / 100, step 105/145, loss = 1.033299\n",
      "epoch 1 / 100, step 106/145, loss = 1.032020\n",
      "epoch 1 / 100, step 107/145, loss = 1.045364\n",
      "epoch 1 / 100, step 108/145, loss = 1.031201\n",
      "epoch 1 / 100, step 109/145, loss = 1.039345\n",
      "epoch 1 / 100, step 110/145, loss = 1.037802\n",
      "epoch 1 / 100, step 111/145, loss = 1.040908\n",
      "epoch 1 / 100, step 112/145, loss = 1.045220\n",
      "epoch 1 / 100, step 113/145, loss = 1.044285\n",
      "epoch 1 / 100, step 114/145, loss = 1.044616\n",
      "epoch 1 / 100, step 115/145, loss = 1.033589\n",
      "epoch 1 / 100, step 116/145, loss = 1.034635\n",
      "epoch 1 / 100, step 117/145, loss = 1.036561\n",
      "epoch 1 / 100, step 118/145, loss = 1.042391\n",
      "epoch 1 / 100, step 119/145, loss = 1.040807\n",
      "epoch 1 / 100, step 120/145, loss = 1.033266\n",
      "epoch 1 / 100, step 121/145, loss = 1.041540\n",
      "epoch 1 / 100, step 122/145, loss = 1.040929\n",
      "epoch 1 / 100, step 123/145, loss = 1.036510\n",
      "epoch 1 / 100, step 124/145, loss = 1.032123\n",
      "epoch 1 / 100, step 125/145, loss = 1.040823\n",
      "epoch 1 / 100, step 126/145, loss = 1.037097\n",
      "epoch 1 / 100, step 127/145, loss = 1.043535\n",
      "epoch 1 / 100, step 128/145, loss = 1.043249\n",
      "epoch 1 / 100, step 129/145, loss = 1.045705\n",
      "epoch 1 / 100, step 130/145, loss = 1.037130\n",
      "epoch 1 / 100, step 131/145, loss = 1.040348\n",
      "epoch 1 / 100, step 132/145, loss = 1.034224\n",
      "epoch 1 / 100, step 133/145, loss = 1.035321\n",
      "epoch 1 / 100, step 134/145, loss = 1.026631\n",
      "epoch 1 / 100, step 135/145, loss = 1.041733\n",
      "epoch 1 / 100, step 136/145, loss = 1.045822\n",
      "epoch 1 / 100, step 137/145, loss = 1.038623\n",
      "epoch 1 / 100, step 138/145, loss = 1.042867\n",
      "epoch 1 / 100, step 139/145, loss = 1.048284\n",
      "epoch 1 / 100, step 140/145, loss = 1.037349\n",
      "epoch 1 / 100, step 141/145, loss = 1.042447\n",
      "epoch 1 / 100, step 142/145, loss = 1.034712\n",
      "epoch 1 / 100, step 143/145, loss = 1.041765\n",
      "epoch 1 / 100, step 144/145, loss = 1.040943\n",
      "epoch 1 / 100, step 145/145, loss = 1.050110\n",
      "Got 1613601/3193600 with acc 50.53\n",
      "Dice score: 0.09909092634916306\n",
      "IoU: 0.052129387855529785\n",
      "epoch 2 / 100, step 1/145, loss = 1.039764\n",
      "epoch 2 / 100, step 2/145, loss = 1.050736\n",
      "epoch 2 / 100, step 3/145, loss = 1.035817\n",
      "epoch 2 / 100, step 4/145, loss = 1.041322\n",
      "epoch 2 / 100, step 5/145, loss = 1.037786\n",
      "epoch 2 / 100, step 6/145, loss = 1.030706\n",
      "epoch 2 / 100, step 7/145, loss = 1.027242\n",
      "epoch 2 / 100, step 8/145, loss = 1.042423\n",
      "epoch 2 / 100, step 9/145, loss = 1.035283\n",
      "epoch 2 / 100, step 10/145, loss = 1.040946\n",
      "epoch 2 / 100, step 11/145, loss = 1.034205\n",
      "epoch 2 / 100, step 12/145, loss = 1.035838\n",
      "epoch 2 / 100, step 13/145, loss = 1.044437\n",
      "epoch 2 / 100, step 14/145, loss = 1.041644\n",
      "epoch 2 / 100, step 15/145, loss = 1.044910\n",
      "epoch 2 / 100, step 16/145, loss = 1.031532\n",
      "epoch 2 / 100, step 17/145, loss = 1.034681\n",
      "epoch 2 / 100, step 18/145, loss = 1.045061\n",
      "epoch 2 / 100, step 19/145, loss = 1.037255\n",
      "epoch 2 / 100, step 20/145, loss = 1.045380\n",
      "epoch 2 / 100, step 21/145, loss = 1.040137\n",
      "epoch 2 / 100, step 22/145, loss = 1.042226\n",
      "epoch 2 / 100, step 23/145, loss = 1.029577\n",
      "epoch 2 / 100, step 24/145, loss = 1.034652\n",
      "epoch 2 / 100, step 25/145, loss = 1.043431\n",
      "epoch 2 / 100, step 26/145, loss = 1.039720\n",
      "epoch 2 / 100, step 27/145, loss = 1.037782\n",
      "epoch 2 / 100, step 28/145, loss = 1.042693\n",
      "epoch 2 / 100, step 29/145, loss = 1.033075\n",
      "epoch 2 / 100, step 30/145, loss = 1.039982\n",
      "epoch 2 / 100, step 31/145, loss = 1.042748\n",
      "epoch 2 / 100, step 32/145, loss = 1.036955\n",
      "epoch 2 / 100, step 33/145, loss = 1.036523\n",
      "epoch 2 / 100, step 34/145, loss = 1.038924\n",
      "epoch 2 / 100, step 35/145, loss = 1.045313\n",
      "epoch 2 / 100, step 36/145, loss = 1.031580\n",
      "epoch 2 / 100, step 37/145, loss = 1.035121\n",
      "epoch 2 / 100, step 38/145, loss = 1.040432\n",
      "epoch 2 / 100, step 39/145, loss = 1.029019\n",
      "epoch 2 / 100, step 40/145, loss = 1.045141\n",
      "epoch 2 / 100, step 41/145, loss = 1.026571\n",
      "epoch 2 / 100, step 42/145, loss = 1.044153\n",
      "epoch 2 / 100, step 43/145, loss = 1.041427\n",
      "epoch 2 / 100, step 44/145, loss = 1.035959\n",
      "epoch 2 / 100, step 45/145, loss = 1.036005\n",
      "epoch 2 / 100, step 46/145, loss = 1.040354\n",
      "epoch 2 / 100, step 47/145, loss = 1.031156\n",
      "epoch 2 / 100, step 48/145, loss = 1.045526\n",
      "epoch 2 / 100, step 49/145, loss = 1.040708\n",
      "epoch 2 / 100, step 50/145, loss = 1.027812\n",
      "epoch 2 / 100, step 51/145, loss = 1.033197\n",
      "epoch 2 / 100, step 52/145, loss = 1.037921\n",
      "epoch 2 / 100, step 53/145, loss = 1.043394\n",
      "epoch 2 / 100, step 54/145, loss = 1.042528\n",
      "epoch 2 / 100, step 55/145, loss = 1.031376\n",
      "epoch 2 / 100, step 56/145, loss = 1.045536\n",
      "epoch 2 / 100, step 57/145, loss = 1.026754\n",
      "epoch 2 / 100, step 58/145, loss = 1.051957\n",
      "epoch 2 / 100, step 59/145, loss = 1.035888\n",
      "epoch 2 / 100, step 60/145, loss = 1.037180\n",
      "epoch 2 / 100, step 61/145, loss = 1.050791\n",
      "epoch 2 / 100, step 62/145, loss = 1.028589\n",
      "epoch 2 / 100, step 63/145, loss = 1.040656\n",
      "epoch 2 / 100, step 64/145, loss = 1.025775\n",
      "epoch 2 / 100, step 65/145, loss = 1.044335\n",
      "epoch 2 / 100, step 66/145, loss = 1.043050\n",
      "epoch 2 / 100, step 67/145, loss = 1.031840\n",
      "epoch 2 / 100, step 68/145, loss = 1.029104\n",
      "epoch 2 / 100, step 69/145, loss = 1.033464\n",
      "epoch 2 / 100, step 70/145, loss = 1.036698\n",
      "epoch 2 / 100, step 71/145, loss = 1.024958\n",
      "epoch 2 / 100, step 72/145, loss = 1.033180\n",
      "epoch 2 / 100, step 73/145, loss = 1.033588\n",
      "epoch 2 / 100, step 74/145, loss = 1.036999\n",
      "epoch 2 / 100, step 75/145, loss = 1.037776\n",
      "epoch 2 / 100, step 76/145, loss = 1.048500\n",
      "epoch 2 / 100, step 77/145, loss = 1.035447\n",
      "epoch 2 / 100, step 78/145, loss = 1.043854\n",
      "epoch 2 / 100, step 79/145, loss = 1.038742\n",
      "epoch 2 / 100, step 80/145, loss = 1.045898\n",
      "epoch 2 / 100, step 81/145, loss = 1.048446\n",
      "epoch 2 / 100, step 82/145, loss = 1.038179\n",
      "epoch 2 / 100, step 83/145, loss = 1.038398\n",
      "epoch 2 / 100, step 84/145, loss = 1.041066\n",
      "epoch 2 / 100, step 85/145, loss = 1.030341\n",
      "epoch 2 / 100, step 86/145, loss = 1.031941\n",
      "epoch 2 / 100, step 87/145, loss = 1.042379\n",
      "epoch 2 / 100, step 88/145, loss = 1.036930\n",
      "epoch 2 / 100, step 89/145, loss = 1.036710\n",
      "epoch 2 / 100, step 90/145, loss = 1.032458\n",
      "epoch 2 / 100, step 91/145, loss = 1.035674\n",
      "epoch 2 / 100, step 92/145, loss = 1.038208\n",
      "epoch 2 / 100, step 93/145, loss = 1.034564\n",
      "epoch 2 / 100, step 94/145, loss = 1.034648\n",
      "epoch 2 / 100, step 95/145, loss = 1.031382\n",
      "epoch 2 / 100, step 96/145, loss = 1.038013\n",
      "epoch 2 / 100, step 97/145, loss = 1.051767\n",
      "epoch 2 / 100, step 98/145, loss = 1.039260\n",
      "epoch 2 / 100, step 99/145, loss = 1.032937\n",
      "epoch 2 / 100, step 100/145, loss = 1.037773\n",
      "epoch 2 / 100, step 101/145, loss = 1.036494\n",
      "epoch 2 / 100, step 102/145, loss = 1.046747\n",
      "epoch 2 / 100, step 103/145, loss = 1.038032\n",
      "epoch 2 / 100, step 104/145, loss = 1.036002\n",
      "epoch 2 / 100, step 105/145, loss = 1.036598\n",
      "epoch 2 / 100, step 106/145, loss = 1.038714\n",
      "epoch 2 / 100, step 107/145, loss = 1.042075\n",
      "epoch 2 / 100, step 108/145, loss = 1.040038\n",
      "epoch 2 / 100, step 109/145, loss = 1.041726\n",
      "epoch 2 / 100, step 110/145, loss = 1.029502\n",
      "epoch 2 / 100, step 111/145, loss = 1.045860\n",
      "epoch 2 / 100, step 112/145, loss = 1.037635\n",
      "epoch 2 / 100, step 113/145, loss = 1.031910\n",
      "epoch 2 / 100, step 114/145, loss = 1.039824\n",
      "epoch 2 / 100, step 115/145, loss = 1.032191\n",
      "epoch 2 / 100, step 116/145, loss = 1.034165\n",
      "epoch 2 / 100, step 117/145, loss = 1.048955\n",
      "epoch 2 / 100, step 118/145, loss = 1.040093\n",
      "epoch 2 / 100, step 119/145, loss = 1.040376\n",
      "epoch 2 / 100, step 120/145, loss = 1.036137\n",
      "epoch 2 / 100, step 121/145, loss = 1.035775\n",
      "epoch 2 / 100, step 122/145, loss = 1.031487\n",
      "epoch 2 / 100, step 123/145, loss = 1.036907\n",
      "epoch 2 / 100, step 124/145, loss = 1.035995\n",
      "epoch 2 / 100, step 125/145, loss = 1.038794\n",
      "epoch 2 / 100, step 126/145, loss = 1.032732\n",
      "epoch 2 / 100, step 127/145, loss = 1.035255\n",
      "epoch 2 / 100, step 128/145, loss = 1.032748\n",
      "epoch 2 / 100, step 129/145, loss = 1.025865\n",
      "epoch 2 / 100, step 130/145, loss = 1.041403\n",
      "epoch 2 / 100, step 131/145, loss = 1.031980\n",
      "epoch 2 / 100, step 132/145, loss = 1.042827\n",
      "epoch 2 / 100, step 133/145, loss = 1.031451\n",
      "epoch 2 / 100, step 134/145, loss = 1.037473\n",
      "epoch 2 / 100, step 135/145, loss = 1.037594\n",
      "epoch 2 / 100, step 136/145, loss = 1.034991\n",
      "epoch 2 / 100, step 137/145, loss = 1.035448\n",
      "epoch 2 / 100, step 138/145, loss = 1.038985\n",
      "epoch 2 / 100, step 139/145, loss = 1.042617\n",
      "epoch 2 / 100, step 140/145, loss = 1.042316\n",
      "epoch 2 / 100, step 141/145, loss = 1.037640\n",
      "epoch 2 / 100, step 142/145, loss = 1.047904\n",
      "epoch 2 / 100, step 143/145, loss = 1.040591\n",
      "epoch 2 / 100, step 144/145, loss = 1.036407\n",
      "epoch 2 / 100, step 145/145, loss = 1.038500\n",
      "Got 1613807/3193600 with acc 50.53\n",
      "Dice score: 0.09923887997865677\n",
      "IoU: 0.0522119514644146\n",
      "epoch 3 / 100, step 1/145, loss = 1.028572\n",
      "epoch 3 / 100, step 2/145, loss = 1.035216\n",
      "epoch 3 / 100, step 3/145, loss = 1.039849\n",
      "epoch 3 / 100, step 4/145, loss = 1.032593\n",
      "epoch 3 / 100, step 5/145, loss = 1.029408\n",
      "epoch 3 / 100, step 6/145, loss = 1.040868\n",
      "epoch 3 / 100, step 7/145, loss = 1.045995\n",
      "epoch 3 / 100, step 8/145, loss = 1.040816\n",
      "epoch 3 / 100, step 9/145, loss = 1.029673\n",
      "epoch 3 / 100, step 10/145, loss = 1.039006\n",
      "epoch 3 / 100, step 11/145, loss = 1.037644\n",
      "epoch 3 / 100, step 12/145, loss = 1.043303\n",
      "epoch 3 / 100, step 13/145, loss = 1.033445\n",
      "epoch 3 / 100, step 14/145, loss = 1.046771\n",
      "epoch 3 / 100, step 15/145, loss = 1.040432\n",
      "epoch 3 / 100, step 16/145, loss = 1.037465\n",
      "epoch 3 / 100, step 17/145, loss = 1.040643\n",
      "epoch 3 / 100, step 18/145, loss = 1.026656\n",
      "epoch 3 / 100, step 19/145, loss = 1.036265\n",
      "epoch 3 / 100, step 20/145, loss = 1.039139\n",
      "epoch 3 / 100, step 21/145, loss = 1.026236\n",
      "epoch 3 / 100, step 22/145, loss = 1.040391\n",
      "epoch 3 / 100, step 23/145, loss = 1.038424\n",
      "epoch 3 / 100, step 24/145, loss = 1.041284\n",
      "epoch 3 / 100, step 25/145, loss = 1.042097\n",
      "epoch 3 / 100, step 26/145, loss = 1.034360\n",
      "epoch 3 / 100, step 27/145, loss = 1.043985\n",
      "epoch 3 / 100, step 28/145, loss = 1.034624\n",
      "epoch 3 / 100, step 29/145, loss = 1.037381\n",
      "epoch 3 / 100, step 30/145, loss = 1.040502\n",
      "epoch 3 / 100, step 31/145, loss = 1.029522\n",
      "epoch 3 / 100, step 32/145, loss = 1.035495\n",
      "epoch 3 / 100, step 33/145, loss = 1.040138\n",
      "epoch 3 / 100, step 34/145, loss = 1.036957\n",
      "epoch 3 / 100, step 35/145, loss = 1.036605\n",
      "epoch 3 / 100, step 36/145, loss = 1.039661\n",
      "epoch 3 / 100, step 37/145, loss = 1.039626\n",
      "epoch 3 / 100, step 38/145, loss = 1.033810\n",
      "epoch 3 / 100, step 39/145, loss = 1.039723\n",
      "epoch 3 / 100, step 40/145, loss = 1.044280\n",
      "epoch 3 / 100, step 41/145, loss = 1.028083\n",
      "epoch 3 / 100, step 42/145, loss = 1.043891\n",
      "epoch 3 / 100, step 43/145, loss = 1.042590\n",
      "epoch 3 / 100, step 44/145, loss = 1.038795\n",
      "epoch 3 / 100, step 45/145, loss = 1.041393\n",
      "epoch 3 / 100, step 46/145, loss = 1.032893\n",
      "epoch 3 / 100, step 47/145, loss = 1.038527\n",
      "epoch 3 / 100, step 48/145, loss = 1.041459\n",
      "epoch 3 / 100, step 49/145, loss = 1.032751\n",
      "epoch 3 / 100, step 50/145, loss = 1.032619\n",
      "epoch 3 / 100, step 51/145, loss = 1.030781\n",
      "epoch 3 / 100, step 52/145, loss = 1.041353\n",
      "epoch 3 / 100, step 53/145, loss = 1.041908\n",
      "epoch 3 / 100, step 54/145, loss = 1.031420\n",
      "epoch 3 / 100, step 55/145, loss = 1.038448\n",
      "epoch 3 / 100, step 56/145, loss = 1.037678\n",
      "epoch 3 / 100, step 57/145, loss = 1.029950\n",
      "epoch 3 / 100, step 58/145, loss = 1.029618\n",
      "epoch 3 / 100, step 59/145, loss = 1.035321\n",
      "epoch 3 / 100, step 60/145, loss = 1.041038\n",
      "epoch 3 / 100, step 61/145, loss = 1.041309\n",
      "epoch 3 / 100, step 62/145, loss = 1.035524\n",
      "epoch 3 / 100, step 63/145, loss = 1.038293\n",
      "epoch 3 / 100, step 64/145, loss = 1.038689\n",
      "epoch 3 / 100, step 65/145, loss = 1.042756\n",
      "epoch 3 / 100, step 66/145, loss = 1.041187\n",
      "epoch 3 / 100, step 67/145, loss = 1.037591\n",
      "epoch 3 / 100, step 68/145, loss = 1.046580\n",
      "epoch 3 / 100, step 69/145, loss = 1.038284\n",
      "epoch 3 / 100, step 70/145, loss = 1.035702\n",
      "epoch 3 / 100, step 71/145, loss = 1.038335\n",
      "epoch 3 / 100, step 72/145, loss = 1.043365\n",
      "epoch 3 / 100, step 73/145, loss = 1.040420\n",
      "epoch 3 / 100, step 74/145, loss = 1.036820\n",
      "epoch 3 / 100, step 75/145, loss = 1.048933\n",
      "epoch 3 / 100, step 76/145, loss = 1.038932\n",
      "epoch 3 / 100, step 77/145, loss = 1.035411\n",
      "epoch 3 / 100, step 78/145, loss = 1.040171\n",
      "epoch 3 / 100, step 79/145, loss = 1.045590\n",
      "epoch 3 / 100, step 80/145, loss = 1.035679\n",
      "epoch 3 / 100, step 81/145, loss = 1.042170\n",
      "epoch 3 / 100, step 82/145, loss = 1.035351\n",
      "epoch 3 / 100, step 83/145, loss = 1.034400\n",
      "epoch 3 / 100, step 84/145, loss = 1.035464\n",
      "epoch 3 / 100, step 85/145, loss = 1.039668\n",
      "epoch 3 / 100, step 86/145, loss = 1.028943\n",
      "epoch 3 / 100, step 87/145, loss = 1.034703\n",
      "epoch 3 / 100, step 88/145, loss = 1.032580\n",
      "epoch 3 / 100, step 89/145, loss = 1.042140\n",
      "epoch 3 / 100, step 90/145, loss = 1.035172\n",
      "epoch 3 / 100, step 91/145, loss = 1.037660\n",
      "epoch 3 / 100, step 92/145, loss = 1.034685\n",
      "epoch 3 / 100, step 93/145, loss = 1.039474\n",
      "epoch 3 / 100, step 94/145, loss = 1.043329\n",
      "epoch 3 / 100, step 95/145, loss = 1.034265\n",
      "epoch 3 / 100, step 96/145, loss = 1.046695\n",
      "epoch 3 / 100, step 97/145, loss = 1.038521\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-dc2e64d90a62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch {epoch+1} / {n_epochs}, step {i+1}/{len(train_loader)}, loss = {loss.item():.6f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m# scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtest_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "criterion1 = nn.BCELoss()\n",
    "criterion2 = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "n_epochs = 100\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer= optimizer, gamma=0.5, verbose = True)\n",
    "\n",
    "test_arr = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "#         print(images.shape, labels.shape)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss1 = criterion1(outputs, labels)\n",
    "        loss2 = criterion2(outputs, labels)\n",
    "        loss = loss1 + loss2\n",
    "        # backward\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 1 ==0:\n",
    "         \n",
    "            print(f'epoch {epoch+1} / {n_epochs}, step {i+1}/{len(train_loader)}, loss = {loss.item():.6f}')\n",
    "    # scheduler.step()\n",
    "    test_arr.append(check_accuracy(test_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PieH_z2dXhI"
   },
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"features\": features,\n",
    "    \"optim_state\": optimizer.state_dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBDgGOVZeFcQ"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_colab_80.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4jnAeh9n0tH"
   },
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score = 0\n",
    "    jaccard = JaccardIndex(num_classes=2, task = 'binary').to(device)\n",
    "    iou = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            y = y.to(device)\n",
    "            x = x.to(device)\n",
    "            preds = model(x)\n",
    "            preds = (preds > 0.5).float()\n",
    "            num_correct +=  (preds ==y).sum()\n",
    "            num_pixels += torch.numel(preds)\n",
    "            dice_score += (2 * (preds * y).sum()) / ((preds + y).sum())\n",
    "            iou += jaccard(preds, y)\n",
    "    \n",
    "    print(f'Cur_iter - {check.cur_iter}')\n",
    "    print(\n",
    "        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n",
    "    )\n",
    "    print(f\"Dice score: {dice_score/len(loader) * 100:.2f}\")\n",
    "    print(f\"IoU: {iou/len(loader) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5YyHlvGPaH6",
    "outputId": "a144c2f2-bda6-47ac-8876-363db44da46d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 22988466/23049600 with acc 99.73\n",
      "Dice score: 0.9972845911979675\n",
      "IoU: 0.9945846199989319\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UGG4bbzcPciN",
    "outputId": "f8c6ef28-79f0-4a50-d644-dcb6b157f11d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 3185224/3195200 with acc 99.69\n",
      "Dice score: 0.9968224763870239\n",
      "IoU: 0.9936651587486267\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(test_loader, model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
